{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from scipy import stats\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score\n",
    "from random import randrange\n",
    "from pandas import Series\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataframes AND Specify a custom delimiter for the CSV input (sep=' ')\n",
    "\n",
    "ecu_dbs_gross=pd.read_csv(r'C:\\Users\\jspad\\Documents\\Code Academy\\EcuBs Project\\OBD2 Doblone.csv', sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14024 entries, 0 to 14023\n",
      "Columns: 201 entries, GPS to (OBD)(km/h)\n",
      "dtypes: float64(184), int64(11), object(6)\n",
      "memory usage: 21.5+ MB\n"
     ]
    }
   ],
   "source": [
    "ecu_dbs_gross.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPS                0\n",
       "Time               0\n",
       "Unnamed: 2         0\n",
       "Device             0\n",
       "Time.1             0\n",
       "               ...  \n",
       "Module)(V)     14024\n",
       "Speed.2        14024\n",
       "(GPS)(km/h)    14024\n",
       "Speed.3        14024\n",
       "(OBD)(km/h)    14024\n",
       "Length: 201, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecu_dbs_gross.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename\n",
    "ecu_dbs_gross=ecu_dbs_gross.rename(columns={\"Longitude\": \"dteday\",\n",
    "                                \"Unnamed: 7\" : \"hr\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-63-75b34f1350d3>:10: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  ecu_dbs_gross['dteday'] = ecu_dbs_gross.apply(lambda r : pd.datetime.combine(r['dteday'],r['hr']),1)\n"
     ]
    }
   ],
   "source": [
    "#Convert time and date into timestamp objects \n",
    "t= ecu_dbs_gross['hr']\n",
    "ecu_dbs_gross['hr'] = pd.to_datetime(t, unit='ns').dt.time\n",
    "\n",
    "d = ecu_dbs_gross['dteday']\n",
    "ecu_dbs_gross['dteday'] = pd.to_datetime(d).dt.date\n",
    "\n",
    "\n",
    "#Combine time and date into one column\n",
    "ecu_dbs_gross['dteday'] = ecu_dbs_gross.apply(lambda r : pd.datetime.combine(r['dteday'],r['hr']),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Columns 1\n",
    "ecu_dbs=ecu_dbs_gross.drop(['GPS','hr','Unnamed: 2','Time.1', 'Time','Unnamed: 5','Device'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecu_dbs=ecu_dbs.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14024 entries, 0 to 14023\n",
      "Data columns (total 60 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   dteday               14024 non-null  datetime64[ns]\n",
      " 1   Latitude             14024 non-null  float64       \n",
      " 2   GPS.1                14024 non-null  float64       \n",
      " 3   Speed                14024 non-null  float64       \n",
      " 4   (Meters/second)      14024 non-null  float64       \n",
      " 5   Unnamed: 12          14024 non-null  float64       \n",
      " 6   Horizontal           14024 non-null  float64       \n",
      " 7   Dilution             14024 non-null  float64       \n",
      " 8   of                   14024 non-null  float64       \n",
      " 9   Precision            14024 non-null  float64       \n",
      " 10  Unnamed: 17          14024 non-null  float64       \n",
      " 11  Altitude             14024 non-null  int64         \n",
      " 12  Unnamed: 19          14024 non-null  int64         \n",
      " 13  Bearing              14024 non-null  int64         \n",
      " 14  Unnamed: 21          14024 non-null  int64         \n",
      " 15  G(x)                 14024 non-null  float64       \n",
      " 16  Unnamed: 23          14024 non-null  float64       \n",
      " 17  G(y)                 14024 non-null  float64       \n",
      " 18  Unnamed: 25          14024 non-null  float64       \n",
      " 19  G(z)                 14024 non-null  float64       \n",
      " 20  Unnamed: 27          14024 non-null  float64       \n",
      " 21  G(calibrated)        14024 non-null  float64       \n",
      " 22  Unnamed: 29          14024 non-null  float64       \n",
      " 23  [FADV]               14024 non-null  int64         \n",
      " 24  Current              14024 non-null  float64       \n",
      " 25  Gear                 14024 non-null  float64       \n",
      " 26  [FADV].1             14024 non-null  float64       \n",
      " 27  Injector             14024 non-null  float64       \n",
      " 28  Duty                 14024 non-null  float64       \n",
      " 29  Cycle(%)             14024 non-null  float64       \n",
      " 30  [FADV].2             14024 non-null  float64       \n",
      " 31  Knock                14024 non-null  float64       \n",
      " 32  Voltage              14024 non-null  float64       \n",
      " 33  Cyl                  14024 non-null  float64       \n",
      " 34  2(mv)                14024 non-null  float64       \n",
      " 35  [FADV].3             14024 non-null  float64       \n",
      " 36  VVT                  14024 non-null  float64       \n",
      " 37  Operation            14024 non-null  float64       \n",
      " 38  Mode                 14024 non-null  float64       \n",
      " 39  [FADV].4             14024 non-null  float64       \n",
      " 40  Waste                14024 non-null  float64       \n",
      " 41  Gate                 14024 non-null  float64       \n",
      " 42  Duty(%)              14024 non-null  float64       \n",
      " 43  Timing               14024 non-null  float64       \n",
      " 44  Advance(Â°)           14024 non-null  float64       \n",
      " 45  Engine               14024 non-null  float64       \n",
      " 46  Load(%)              14024 non-null  float64       \n",
      " 47  Engine.1             14024 non-null  float64       \n",
      " 48  Load(Absolute)(%)    14024 non-null  float64       \n",
      " 49  Kilometers           14024 non-null  float64       \n",
      " 50  Per                  14024 non-null  float64       \n",
      " 51  Litre(Instant)(kpl)  14024 non-null  float64       \n",
      " 52  Fuel                 14024 non-null  int64         \n",
      " 53  Trim                 14024 non-null  float64       \n",
      " 54  Bank                 14024 non-null  int64         \n",
      " 55  1                    14024 non-null  int64         \n",
      " 56  Long                 14024 non-null  float64       \n",
      " 57  Term(%)              14024 non-null  float64       \n",
      " 58  Fuel.1               14024 non-null  float64       \n",
      " 59  Trim.1               14024 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(50), int64(9)\n",
      "memory usage: 6.4 MB\n"
     ]
    }
   ],
   "source": [
    "ecu_dbs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging datasets\n",
    "\n",
    "# part_df=pd.merge(products, stock, on=\"index_col\")\n",
    "# part_df=part_df.drop(['ASIN_y'], axis=1)\n",
    "\n",
    "# part2_df=pd.merge(part_df, assessment, on=\"index_col\")\n",
    "# part2_df=part2_df.drop(['ASIN_x'], axis=1)\n",
    "\n",
    "# part3_df=pd.merge(part2_df, invoices, on=\"index_col\")\n",
    "# part3_df=part3_df.drop(['ASIN_y'], axis=1)\n",
    "\n",
    "# full_df=pd.merge(part3_df, customers, on=\"index_col\")\n",
    "# full_df=full_df.drop(['CustomerID_y', 'index_col'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns\n",
    "\n",
    "# df=df.drop(['invoice_time', 'StockCode'], axis=1)\n",
    "\n",
    "# # Data cleaning - checking missing values (Customerid missing) \n",
    "# #np.issubdtype(df['CustomerID_x'].dtype, np.number)\n",
    "\n",
    "# df=df[pd.to_numeric(df['CustomerID_x'], errors='coerce').notnull()]\n",
    "\n",
    "# # Data cleaning - checking missing values (Customerid missing) \n",
    "\n",
    "# df_country=df[pd.to_numeric(df['CustomerID_x'], errors='coerce').notnull()]\n",
    "\n",
    "# # Rename\n",
    "# df=df.rename(columns={\"title\": \"Description\",\n",
    "#                                 \"ASIN_x\": \"ASIN\",\n",
    "#                                 \"CustomerID_x\": \"CustomerID\"})\n",
    "\n",
    "# # Transforming these labels into categrical data type\n",
    "\n",
    "# df['product_type'] = pd.Categorical(df['product_type'],\n",
    "# categories=['dslr camera', 'keyboard', 'monitor', 'mouse', 'processor', 'smartphone',])\n",
    "\n",
    "\n",
    "# df['Country'] = pd.Categorical(df['Country'],\n",
    "# categories=['Australia','Austria','Bahrain','Belgium','Brazil','Canada','Cyprus','Czech Republic','Denmark','European Community','Finland','France','Germany','Greece',\n",
    "#             'Iceland','Ireland','Israel','Italy','Japan','Lebanon','Lithuania','Malta','Netherlands','Norway','Poland','Portugal','Saudi Arabia','Singapore',\n",
    "#             'South Africa','Spain','Sweden','Switzerland','United Arab Emirates','United Kingdom','United States','Unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot tabel per Customer\n",
    "\n",
    "# table_customer = pd.pivot_table(df, values='total_sale', index=['CustomerID', 'Country', 'product_type'],\n",
    "#                     aggfunc=np.sum,\n",
    "#                     observed=True)\n",
    "\n",
    "# table_customer=table_customer.sort_values(by=['total_sale'], ascending=False)\n",
    "\n",
    "# table_customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_sales=df.groupby('CustomerID')['total_sale'].agg(['sum','count','mean']).sort_values(by=['sum'], ascending=False)\n",
    "\n",
    "# t_sales.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot tabel per Category of Product\n",
    "\n",
    "# table_product = pd.pivot_table(df_country, values='total_sale', index=[ 'product_type'],\n",
    "#                     aggfunc=np.sum,\n",
    "#                     observed=True)\n",
    "\n",
    "# table_product=table_product.sort_values(by=['total_sale'], ascending=False)\n",
    "\n",
    "# table_product.sort_values(by=['total_sale'], ascending=False).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Which countries and which customers made the highest number of orders? Are they the same with the highest spending?\n",
    "\n",
    "\n",
    "# country_sales=df_country.groupby('Country')['total_sale'].agg(['sum','count','mean']).sort_values(by=['count'], ascending=False)\n",
    "\n",
    "# country_sales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # IRQ\n",
    "\n",
    "# # Select the first quantile\n",
    "# q1 =df['total_sale'].quantile(.25)\n",
    "\n",
    "# # Select the third quantile\n",
    "# q3 = df['total_sale'].quantile(.75)\n",
    "\n",
    "# # Create a mask inbeetween q1 & q3\n",
    "# mask = df['total_sale'].between(q1, q3, inclusive=True)\n",
    "\n",
    "# # Filtering the initial dataframe with a mask\n",
    "# iqr = df.loc[mask, 'total_sale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of         total_sale        invoice_date\n",
       "1           159.96 2018-12-01 17:00:00\n",
       "3           199.99 2018-12-01 17:00:00\n",
       "5           335.86 2018-12-01 17:00:00\n",
       "6            71.70 2018-12-01 17:00:00\n",
       "7           395.00 2018-12-01 17:00:00\n",
       "...            ...                 ...\n",
       "554411      543.68 2019-12-09 08:00:00\n",
       "554412      179.88 2019-12-09 08:00:00\n",
       "554413      179.94 2019-12-09 08:00:00\n",
       "554414       83.64 2019-12-09 08:00:00\n",
       "554415      279.80 2019-12-09 08:00:00\n",
       "\n",
       "[206005 rows x 2 columns]>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a filtered DF\n",
    "\n",
    "# df2=df.drop(['Description',\t'product_type', 'rating', 'review_count', 'ASIN', 'InvoiceNo', 'Quantity','price', 'CustomerID', 'Country'], axis=1)\n",
    "# df_filtered = df2[df2['total_sale'] <= 648]\n",
    "# df_filtered2 = df_filtered[df_filtered['total_sale'] >= 60]\n",
    "# df_filtered2.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reset"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ab92f9d484bccba0f50fef4945cfa2ff18621070182d288e11e1b27e8c09bd3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
